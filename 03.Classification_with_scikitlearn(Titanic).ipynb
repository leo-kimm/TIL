{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpjgOJc_Uc4h"
   },
   "source": [
    "## Machine Learning ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpjgOJc_Uc4h"
   },
   "source": [
    "### íƒ€ì´íƒ€ë‹‰ íƒ‘ìŠ¹ê° ìƒì¡´ ì˜ˆì¸¡ Classification with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iQh-XIEeUc4l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.2-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.30.1-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=bec303e5fe43e30a599201a6c41bc6d5b5e2f63aa271668a3beef72eccaa7267\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=9784f89f2af2e478a1467497d41254dfb62fbda4a22c00283a3d7cf9e73d5294\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.30.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 opt-einsum-3.3.0 protobuf-3.17.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: c:\\users\\admin\\anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: c:\\users\\admin\\anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for jpype1: [Errno 2] No such file or directory: 'c:\\\\users\\\\admin\\\\anaconda3\\\\lib\\\\site-packages\\\\JPype1-1.2.1.dist-info\\\\METADATA'\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: c:\\users\\admin\\anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: c:\\users\\admin\\anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e6a9b94ed7c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#classification(ë¶„ë¥˜)\n",
    "from sklearn.tree import DecisionTreeClassifier      #ì˜ì‚¬ê²°ì •íŠ¸ë¦¬\n",
    "from sklearn.ensemble import RandomForestClassifier  #ëœë¤í¬ë ˆìŠ¤íŠ¸\n",
    "from sklearn.neighbors import KNeighborsClassifier   #KNN(K_Nearst_Neighbor)K-ìµœê·¼ì ‘ì´ì›ƒ\n",
    "from sklearn.linear_model import LogisticRegression  #ë¡œì§€ìŠ¤í‹±íšŒê·€\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6W_6ylVUc4x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. ë°ì´í„° í™•ì¸í•˜ê¸°\n",
    "df = pd.read_csv('../ML/03Titanic_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOpYsOrkUc45"
   },
   "outputs": [],
   "source": [
    "# 3. ë¹ ì§„ ê°’ í™•ì¸\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUQWDhI-Uc4_"
   },
   "outputs": [],
   "source": [
    "# 4. ì‚¬ìš©í•˜ì§€ ì•Šì„ feature ì œê±°\n",
    "feature = df.drop(['survived','name', 'ticket','boat','body','home.dest','cabin'], axis=1)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleImputerë¡œ ë§Œë“  í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# numeric(fare, age) -mean\n",
    "mean_imputer = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "def f_mean_imputer(df, i):\n",
    "    mean_imputer.fit(feature.iloc[:, i:i+1]) # í•´ë‹¹ ì—´ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´\n",
    "    feature.iloc[:, i:i+1] = mean_imputer.transform(df.iloc[:, i:i+1])\n",
    "    return df.isnull().sum()\n",
    "\n",
    "# Clean Missing Data 2 - string(embarked) -most_frequent\n",
    "mode_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "def f_mode_imputer(df, i):\n",
    "    mode_imputer.fit(feature.iloc[:,:i+1]) # í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "    feature.iloc[:, :i+1] = mode_imputer.transform(df.iloc[:,:i+1])\n",
    "    return df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HU4XOrk3Uc5Q"
   },
   "outputs": [],
   "source": [
    "# 5. Impute - Fare\n",
    "f_mean_imputer(feature, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtOmNtSlUc5b"
   },
   "outputs": [],
   "source": [
    "# 6. Impute - Age\n",
    "f_mean_imputer(feature, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3H-VZLiUc5l"
   },
   "outputs": [],
   "source": [
    "# 7. Impute - Embarked\n",
    "f_mode_imputer(feature, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L20zaD8AUc5x"
   },
   "outputs": [],
   "source": [
    "# 8. Feature Heatmap ì‹œê°í™”ì— ì•ì„œ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature Heatmap ì‹œê°í™”\n",
    "# feature heatmap ê·¸ë ¤ë³´ê¸°\n",
    "featurecorr = feature.corr()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(featurecorr, cmap='viridis')\n",
    "#sns.heatmap(df_17corr, annot=True, fmt='f')\n",
    "plt.title('Heatmap of featurecorr by seaborn', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5RxKjVqUc6M"
   },
   "outputs": [],
   "source": [
    "# 8-1. ì‹œê°í™” - ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ì ìˆ˜\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='gender', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kGaVHKiUc6T"
   },
   "outputs": [],
   "source": [
    "# 8-2 ì‹œê°í™” - ì„ ì‹¤ ë“±ê¸‰ì— ë”°ë¥¸ ìƒì¡´ì—¬ë¶€\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='embarked', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-3 ì‹œê°í™” - ìë§¤ì—¬ë¶€ì— ë”°ë¥¸ ìƒì¡´ì—¬ë¶€\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='sibsp', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-4 ì‹œê°í™” - ë¶€ëª¨ìì‹ì— ë”°ë¥¸ ìƒì¡´ì—¬ë¶€\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='parch', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqPvNkQLUc6h"
   },
   "outputs": [],
   "source": [
    "# 9. X/y  ë¶„ë¦¬\n",
    "# ì¢…ì† ë³€ìˆ˜ë¥¼ ë‹´ëŠ” ë“¯\n",
    "y = df['survived']\n",
    "\n",
    "# í•„ìš”ì—†ëŠ” ë³€ìˆ˜ë“¤ì„ ì œê±°í•˜ê³  xì¶• ë…ë¦½ë³€ìˆ˜ë“¤ë¡œ ë§Œë“¬\n",
    "#x = transform_features(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S443vMv5Uc6c"
   },
   "outputs": [],
   "source": [
    "# 10. ë°ì´í„° ë³€í™˜(one hot encoding)\n",
    "# gender ë¬¸ìì—´ì´ë‹ˆê¹Œ ìˆ«ìë¡œ ë°”ê¿”ì£¼ê¸°\n",
    "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(),[1,6])], remainder='passthrough')\n",
    "\n",
    "feature = ct.fit_transform(feature)\n",
    "\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTlQfecgUc6k"
   },
   "outputs": [],
   "source": [
    "# 11. í›ˆë ¨ì…‹/í‰ê°€ì…‹ ë¶„ë¦¬\n",
    "\n",
    "\n",
    "# train_test_splitìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ ì¤Œ\n",
    "# test_sizeë¡œ trainê³¼ test ë°ì´í„°ì˜ ë¹„ìœ¨ì„ ì„¤ì •í•  ìˆ˜ ìˆìŒ (default = 0.25)\n",
    "# train_sizeë„ ì„¤ì •ê°€ëŠ¥ (default = 1-test_size)\n",
    "# random_stateë¡œ ì…”í”Œì„ ìœ„í•œ seed ê°’ì„ ì§€ì •í•  ìˆ˜ ìˆìŒ(intë¡œë„ ì…ë ¥ê°€ëŠ¥)\n",
    "# shuffleë„ ì„¤ì •ê°€ëŠ¥. ë°ì´í„° ì„ì„ê±´ì§€ (default = True)\n",
    "# stratifyë„ ì„¤ì •ê°€ëŠ¥ í•˜ë©° classificationì„ ë‹¤ë£°ë•Œ í•„ìš”í•¨. í•œìª½ì— ì¹˜ì¤‘ë˜ëŠ” ê²ƒì„ ë°©ì§€ (default = None)\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmiqcnijUc6q"
   },
   "outputs": [],
   "source": [
    "# 12. ëª¨ë¸ í•™ìŠµ\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "log_clf = LogisticRegression()\n",
    "XGB_clf = XGBClassifier()\n",
    "\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZmcThlRUc6v"
   },
   "outputs": [],
   "source": [
    "# 13. ëª¨ë¸ ì„±ëŠ¥ í™•ì¸(evaluate)\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print('mae = ',mae)\n",
    "print('mse = ',mse)\n",
    "print('r2 = ',r2)\n",
    "print('accuracy = ',acc)\n",
    "print('precision = ',pre)\n",
    "print('recall = ',rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJiHZ_v5Uc61"
   },
   "outputs": [],
   "source": [
    "# 13-1. confusion matrix í™•ì¸\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(rf_clf, x_train, y_train, cv=3)\n",
    "cf = confusion_matrix(y_train, y_train_pred)\n",
    "print(cf)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nB3uyQKtHY6"
   },
   "source": [
    "ğŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Classification_with_scikitlearn(Titanic).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
