{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpjgOJc_Uc4h"
   },
   "source": [
    "## Machine Learning 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpjgOJc_Uc4h"
   },
   "source": [
    "### 타이타닉 탑승객 생존 예측 Classification with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iQh-XIEeUc4l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.2-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.30.1-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=bec303e5fe43e30a599201a6c41bc6d5b5e2f63aa271668a3beef72eccaa7267\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=9784f89f2af2e478a1467497d41254dfb62fbda4a22c00283a3d7cf9e73d5294\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.30.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 opt-einsum-3.3.0 protobuf-3.17.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: c:\\users\\admin\\anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: c:\\users\\admin\\anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for jpype1: [Errno 2] No such file or directory: 'c:\\\\users\\\\admin\\\\anaconda3\\\\lib\\\\site-packages\\\\JPype1-1.2.1.dist-info\\\\METADATA'\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: c:\\users\\admin\\anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: c:\\users\\admin\\anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e6a9b94ed7c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "# 1. 데이터 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#classification(분류)\n",
    "from sklearn.tree import DecisionTreeClassifier      #의사결정트리\n",
    "from sklearn.ensemble import RandomForestClassifier  #랜덤포레스트\n",
    "from sklearn.neighbors import KNeighborsClassifier   #KNN(K_Nearst_Neighbor)K-최근접이웃\n",
    "from sklearn.linear_model import LogisticRegression  #로지스틱회귀\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6W_6ylVUc4x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. 데이터 확인하기\n",
    "df = pd.read_csv('../ML/03Titanic_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOpYsOrkUc45"
   },
   "outputs": [],
   "source": [
    "# 3. 빠진 값 확인\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUQWDhI-Uc4_"
   },
   "outputs": [],
   "source": [
    "# 4. 사용하지 않을 feature 제거\n",
    "feature = df.drop(['survived','name', 'ticket','boat','body','home.dest','cabin'], axis=1)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleImputer로 만든 함수 가져오기\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# numeric(fare, age) -mean\n",
    "mean_imputer = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "def f_mean_imputer(df, i):\n",
    "    mean_imputer.fit(feature.iloc[:, i:i+1]) # 해당 열의 평균으로 대체\n",
    "    feature.iloc[:, i:i+1] = mean_imputer.transform(df.iloc[:, i:i+1])\n",
    "    return df.isnull().sum()\n",
    "\n",
    "# Clean Missing Data 2 - string(embarked) -most_frequent\n",
    "mode_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "def f_mode_imputer(df, i):\n",
    "    mode_imputer.fit(feature.iloc[:,:i+1]) # 해당 열의 최빈값으로 대체\n",
    "    feature.iloc[:, :i+1] = mode_imputer.transform(df.iloc[:,:i+1])\n",
    "    return df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HU4XOrk3Uc5Q"
   },
   "outputs": [],
   "source": [
    "# 5. Impute - Fare\n",
    "f_mean_imputer(feature, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtOmNtSlUc5b"
   },
   "outputs": [],
   "source": [
    "# 6. Impute - Age\n",
    "f_mean_imputer(feature, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3H-VZLiUc5l"
   },
   "outputs": [],
   "source": [
    "# 7. Impute - Embarked\n",
    "f_mode_imputer(feature, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L20zaD8AUc5x"
   },
   "outputs": [],
   "source": [
    "# 8. Feature Heatmap 시각화에 앞서 모듈 가져오기\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature Heatmap 시각화\n",
    "# feature heatmap 그려보기\n",
    "featurecorr = feature.corr()\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(featurecorr, cmap='viridis')\n",
    "#sns.heatmap(df_17corr, annot=True, fmt='f')\n",
    "plt.title('Heatmap of featurecorr by seaborn', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5RxKjVqUc6M"
   },
   "outputs": [],
   "source": [
    "# 8-1. 시각화 - 성별에 따른 생존자 수\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='gender', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kGaVHKiUc6T"
   },
   "outputs": [],
   "source": [
    "# 8-2 시각화 - 선실 등급에 따른 생존여부\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='embarked', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-3 시각화 - 자매여부에 따른 생존여부\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='sibsp', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-4 시각화 - 부모자식에 따른 생존여부\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot('survived', hue='parch', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqPvNkQLUc6h"
   },
   "outputs": [],
   "source": [
    "# 9. X/y  분리\n",
    "# 종속 변수를 담는 듯\n",
    "y = df['survived']\n",
    "\n",
    "# 필요없는 변수들을 제거하고 x축 독립변수들로 만듬\n",
    "#x = transform_features(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S443vMv5Uc6c"
   },
   "outputs": [],
   "source": [
    "# 10. 데이터 변환(one hot encoding)\n",
    "# gender 문자열이니까 숫자로 바꿔주기\n",
    "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(),[1,6])], remainder='passthrough')\n",
    "\n",
    "feature = ct.fit_transform(feature)\n",
    "\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTlQfecgUc6k"
   },
   "outputs": [],
   "source": [
    "# 11. 훈련셋/평가셋 분리\n",
    "\n",
    "\n",
    "# train_test_split으로 데이터를 나눠줌\n",
    "# test_size로 train과 test 데이터의 비율을 설정할 수 있음 (default = 0.25)\n",
    "# train_size도 설정가능 (default = 1-test_size)\n",
    "# random_state로 셔플을 위한 seed 값을 지정할 수 있음(int로도 입력가능)\n",
    "# shuffle도 설정가능. 데이터 섞을건지 (default = True)\n",
    "# stratify도 설정가능 하며 classification을 다룰때 필요함. 한쪽에 치중되는 것을 방지 (default = None)\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmiqcnijUc6q"
   },
   "outputs": [],
   "source": [
    "# 12. 모델 학습\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "log_clf = LogisticRegression()\n",
    "XGB_clf = XGBClassifier()\n",
    "\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZmcThlRUc6v"
   },
   "outputs": [],
   "source": [
    "# 13. 모델 성능 확인(evaluate)\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print('mae = ',mae)\n",
    "print('mse = ',mse)\n",
    "print('r2 = ',r2)\n",
    "print('accuracy = ',acc)\n",
    "print('precision = ',pre)\n",
    "print('recall = ',rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJiHZ_v5Uc61"
   },
   "outputs": [],
   "source": [
    "# 13-1. confusion matrix 확인\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(rf_clf, x_train, y_train, cv=3)\n",
    "cf = confusion_matrix(y_train, y_train_pred)\n",
    "print(cf)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nB3uyQKtHY6"
   },
   "source": [
    "😊"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Classification_with_scikitlearn(Titanic).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
